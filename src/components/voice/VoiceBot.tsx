'use client';

import { useState, useEffect, useRef } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import { Mic, MicOff, Volume2, Loader2 } from 'lucide-react';
import { NewVoiceWidget } from '@/components/voice/NewVoiceWidget';
import { cn } from '@/lib/utils';
import { playStreamingTTS, fallbackTextToSpeech, isStreamingSupported } from '@/utils/streamingTTS';
import type { VoiceBotProps, BotConfig, VoiceSession } from '@/types';

export function VoiceBot({
  agentId,
  mode = 'embedded',
  size = 'normal',
  className,
  customTheme
}: VoiceBotProps) {
  const [config, setConfig] = useState<BotConfig | null>(null);
  const [session, setSession] = useState<VoiceSession | null>(null);
  const [isLoading, setIsLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);

  // Ø¬Ù„Ø¨ ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø¨ÙˆØª
  useEffect(() => {
    fetchBotConfig();
  }, [agentId]);

  const fetchBotConfig = async () => {
    try {
      setIsLoading(true);

      const response = await fetch(`/api/bot/config/${agentId}`);
      const result = await response.json();

      if (result.success && result.data) {
        const botConfig: BotConfig = {
          agentId,
          name: result.data.name || 'Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ',
          avatarEmoji: result.data.avatar_emoji || 'ğŸ¤–',
          voiceId: result.data.voice_id || 'ar-male-1',
          welcomeMessage: result.data.welcome_message || '',
          isActive: result.data.is_active || true,
          createdAt: result.data.created_at || new Date().toISOString(),
          updatedAt: result.data.updated_at || new Date().toISOString(),
        };
        setConfig(botConfig);
      } else {
        throw new Error('Failed to fetch config');
      }
    } catch (err) {
      setError('ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯');
      console.error('Error fetching bot config:', err);
    } finally {
      setIsLoading(false);
    }
  };

  const startVoiceSession = async () => {
    if (!config) return;

    try {
      // Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø© Ø¹Ø¨Ø± API
      const formData = new FormData();
      formData.append('agentId', agentId);

      const response = await fetch('/api/voice/start', {
        method: 'POST',
        body: formData
      });

      const result = await response.json();

      if (!result.success) {
        throw new Error(result.error || 'ÙØ´Ù„ ÙÙŠ Ø¨Ø¯Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©');
      }

      // Ø¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù† Ø§Ù„Ø¬Ù„Ø³Ø©
      const newSession: VoiceSession = {
        sessionId: result.data.sessionId,
        agentId,
        isListening: false,
        isProcessing: false,
        isPlaying: false,
        messages: [],
      };

      setSession(newSession);
      
      // ØªØ´ØºÙŠÙ„ Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨
      await playWelcomeMessage();
      
      // Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹
      await startListening();
    } catch (err) {
      setError('ÙØ´Ù„ ÙÙŠ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©');
      console.error('Error starting voice session:', err);
    }
  };

  // ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Streaming API Ù…Ø¹ fallback
  const textToSpeech = async (text: string, voiceId: string): Promise<string | null> => {
    try {
      // Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Streaming API Ø£ÙˆÙ„Ø§Ù‹ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø¯Ø¹ÙˆÙ…Ø§Ù‹
      if (isStreamingSupported()) {
        console.log('Ø§Ø³ØªØ®Ø¯Ø§Ù… Streaming TTS API ÙÙŠ VoiceBot');
        await playStreamingTTS(text, voiceId, (progress) => {
          console.log(`ØªÙ‚Ø¯Ù… Ø§Ù„ØªØ´ØºÙŠÙ„: ${Math.round(progress * 100)}%`);
        });
        return null; // Ø¥Ø´Ø§Ø±Ø© Ø£Ù† Ø§Ù„ØµÙˆØª ØªÙ… ØªØ´ØºÙŠÙ„Ù‡ Ù…Ø¨Ø§Ø´Ø±Ø©
      } else {
        console.log('Streaming ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…ØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ©');
        // fallback Ù„Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ©
        return await fallbackTextToSpeech(text, voiceId);
      }
    } catch (error) {
      console.warn('ÙØ´Ù„ ÙÙŠ Streaming TTSØŒ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ©:', error);
      
      try {
        // Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ© ÙƒÙ€ fallback
        return await fallbackTextToSpeech(text, voiceId);
      } catch (fallbackError) {
        console.error('ÙØ´Ù„ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø·Ø±Ù‚ TTS:', fallbackError);
        throw fallbackError;
      }
    }
  };

  // ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
  const playAudio = (audioUrl: string): Promise<void> => {
    return new Promise((resolve, reject) => {
      const audio = new Audio(audioUrl);
      
      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ Ø§Ù„Ù€ URL Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† blob URL Ø£Ù… Ù„Ø§
      const isBlobUrl = audioUrl.startsWith('blob:');
      
      audio.onended = () => {
        // ØªØ­Ø±ÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† blob URL
        if (isBlobUrl) {
          URL.revokeObjectURL(audioUrl);
        }
        resolve();
      };
      
      audio.onerror = (error) => {
        // ØªØ­Ø±ÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† blob URL
        if (isBlobUrl) {
          URL.revokeObjectURL(audioUrl);
        }
        reject(error);
      };
      
      audio.play().catch(reject);
    });
  };

  const playWelcomeMessage = async () => {
    if (!config || !session) return;

    // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨
    if (!config.welcomeMessage || !config.welcomeMessage.trim()) {
      console.log('No welcome message configured');
      return;
    }
    
    setSession(prev => prev ? { ...prev, isPlaying: true } : null);
    
    try {
      // ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Streaming TTS
      console.log('Generating welcome message using Streaming TTS');
      const audioUrl = await textToSpeech(config.welcomeMessage, config.voiceId);
      
      // ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª ÙÙ‚Ø· Ø¥Ø°Ø§ ØªÙ… Ø¥Ø±Ø¬Ø§Ø¹ URL (Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ©)
      if (audioUrl) {
        await playAudio(audioUrl);
      }
      // Ø¥Ø°Ø§ ÙƒØ§Ù† audioUrl Ù‡Ùˆ nullØŒ ÙÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† streaming ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙˆØªÙ… Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ø§Ù„ÙØ¹Ù„
    } catch (err) {
      console.error('Error playing welcome message:', err);
      // Ù…Ø­Ø§ÙƒØ§Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„
      await new Promise(resolve => setTimeout(resolve, 2000));
    } finally {
      setSession(prev => prev ? { ...prev, isPlaying: false } : null);
    }
  };



  const startListening = async () => {
    if (!session) return;

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      
      const audioChunks: Blob[] = [];
      
      mediaRecorder.ondataavailable = (event) => {
        audioChunks.push(event.data);
      };
      
      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
        await processVoiceInput(audioBlob);
      };
      
      mediaRecorder.start();
      setSession(prev => prev ? { ...prev, isListening: true } : null);
      
      // Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¨Ø¹Ø¯ ØµÙ…Øª (Ù…Ø­Ø§ÙƒØ§Ø©)
      setTimeout(() => {
        if (mediaRecorderRef.current?.state === 'recording') {
          mediaRecorderRef.current.stop();
        }
      }, 5000);
      
    } catch (err) {
      setError('ÙØ´Ù„ ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†');
      console.error('Error starting listening:', err);
    }
  };

  const processVoiceInput = async (audioBlob: Blob) => {
    if (!session) return;

    setSession(prev => prev ? { 
      ...prev, 
      isListening: false, 
      isProcessing: true 
    } : null);

    try {
      // TODO: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª Ø¹Ø¨Ø± API
      // 1. ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ (Gladia)
      // 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ (Gemini + RAG)
      // 3. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø±Ø¯ Ø¥Ù„Ù‰ ØµÙˆØª (ElevenLabs)
      
      // Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
      await new Promise(resolve => setTimeout(resolve, 3000));
      
      const mockResponse = 'Ø´ÙƒØ±Ø§Ù‹ Ù„Ùƒ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„Ùƒ. Ù‡Ø°Ø§ Ø±Ø¯ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ.';
      
      // ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¯
      setSession(prev => prev ? { 
        ...prev, 
        isProcessing: false,
        isPlaying: true 
      } : null);
      
      // Ù…Ø­Ø§ÙƒØ§Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¯
      await new Promise(resolve => setTimeout(resolve, 2000));
      
      // Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ø§Ø³ØªÙ…Ø§Ø¹
      setSession(prev => prev ? { 
        ...prev, 
        isPlaying: false 
      } : null);
      
      // Ø¨Ø¯Ø¡ Ø¯ÙˆØ±Ø© Ø§Ø³ØªÙ…Ø§Ø¹ Ø¬Ø¯ÙŠØ¯Ø©
      setTimeout(() => startListening(), 1000);
      
    } catch (err) {
      setError('ÙØ´Ù„ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª');
      console.error('Error processing voice input:', err);
      setSession(prev => prev ? { 
        ...prev, 
        isProcessing: false 
      } : null);
    }
  };

  const stopSession = async () => {
    if (mediaRecorderRef.current?.state === 'recording') {
      mediaRecorderRef.current.stop();
    }

    // Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
    if (session?.sessionId) {
      try {
        const formData = new FormData();
        formData.append('sessionId', session.sessionId);

        await fetch('/api/voice/end', {
          method: 'POST',
          body: formData
        });
      } catch (error) {
        console.error('Error ending session:', error);
      }
    }

    setSession(null);
  };

  if (isLoading) {
    return (
      <div className={cn(
        'flex items-center justify-center',
        size === 'large' ? 'w-32 h-32' : 'w-16 h-16',
        className
      )}>
        <Loader2 className="w-8 h-8 animate-spin text-blue-400" />
      </div>
    );
  }

  if (error || !config) {
    return (
      <div className={cn(
        'flex items-center justify-center bg-red-500/20 rounded-full border border-red-500/50',
        size === 'large' ? 'w-32 h-32' : 'w-16 h-16',
        className
      )}>
        <MicOff className="w-8 h-8 text-red-400" />
      </div>
    );
  }

  const buttonSize = size === 'large' ? 128 : 64;
  const iconSize = size === 'large' ? 32 : 20;

  return (
    <div className={cn('relative', className)}>
      <NewVoiceWidget
        agentId={agentId}
        name={config.name}
        avatarEmoji={config.avatarEmoji}
        voiceId={config.voiceId}
        welcomeMessage={config.welcomeMessage}
        mode={mode}
      />
      
      {/* Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø¹Ø§ÙŠÙ†Ø© */}
      {mode === 'preview' && session && (
        <motion.div
          className="absolute -bottom-12 left-1/2 transform -translate-x-1/2"
          initial={{ opacity: 0, y: 10 }}
          animate={{ opacity: 1, y: 0 }}
        >
          <div className="bg-black/50 backdrop-blur-sm rounded-lg px-3 py-1 text-sm text-white">
            {session.isListening && 'ÙŠØ³ØªÙ…Ø¹...'}
            {session.isProcessing && 'ÙŠØ¹Ø§Ù„Ø¬...'}
            {session.isPlaying && 'ÙŠØªØ­Ø¯Ø«...'}
          </div>
        </motion.div>
      )}
    </div>
  );
}
